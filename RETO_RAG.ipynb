{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0ea4eedc",
      "metadata": {
        "id": "0ea4eedc"
      },
      "source": [
        "## 0. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0c07e509",
      "metadata": {
        "id": "0c07e509"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any\n",
        "from datetime import datetime\n",
        "\n",
        "# LangChain core\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "# Vector store (usando la versi√≥n community en lugar de langchain_chroma)\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "# Loaders\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader, UnstructuredFileLoader\n",
        "\n",
        "# OpenAI\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ulgJAyE6k9br",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulgJAyE6k9br",
        "outputId": "bc52a16d-141d-4f2e-d4e0-1ebe2ead5f00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ API Key configurada correctamente\n"
          ]
        }
      ],
      "source": [
        "# Configuraci√≥n de la API Key de OpenAI\n",
        "import os\n",
        "\n",
        "# üîë Opci√≥n 1: Def√≠nela manualmente aqu√≠ (no recomendado en notebooks p√∫blicos)\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"tu_api_key_aqui\"\n",
        "\n",
        "# üîë Opci√≥n 2 (recomendada): si est√°s en Colab, usa el gestor de secretos\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "except Exception as e:\n",
        "    # Si no est√°s en Colab, intenta leer de variable local\n",
        "    openai_api_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
        "    if not openai_api_key:\n",
        "        raise ValueError(\"‚ùå No se encontr√≥ OPENAI_API_KEY. Def√≠nela antes de continuar.\")\n",
        "\n",
        "print(\"‚úÖ API Key configurada correctamente\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22e19bdb",
      "metadata": {
        "id": "22e19bdb"
      },
      "source": [
        "## 1. Extracting files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "SOtbwefdlMur",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOtbwefdlMur",
        "outputId": "05bf0dee-7d33-4025-88a0-e4ef33993d4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Directorios listos\n",
            "üìÇ DATA_DIR: /content/data\n",
            "üìÇ PERSIST_DIR: /content/data/chroma\n"
          ]
        }
      ],
      "source": [
        "# Definir directorios de trabajo\n",
        "\n",
        "# Carpeta donde estar√°n los documentos (definida en Celda 4 tambi√©n)\n",
        "DATA_DIR = Path(\"./data\")\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Carpeta donde se guardar√° la base vectorial Chroma\n",
        "PERSIST_DIR = Path(\"./data/chroma\")\n",
        "PERSIST_DIR.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "print(\"‚úÖ Directorios listos\")\n",
        "print(\"üìÇ DATA_DIR:\", DATA_DIR.resolve())\n",
        "print(\"üìÇ PERSIST_DIR:\", PERSIST_DIR.resolve())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "VXTU4Su0lTNb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXTU4Su0lTNb",
        "outputId": "b981a4f4-ca2e-4eff-cddd-5387efd7d8ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Entorno listo. Los documentos se tomar√°n desde: /content/data\n",
            "üì¶ Archivos detectados en ./data:\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Carpeta donde deben estar tus documentos (PDF, DOCX, TXT, MD, HTML)\n",
        "DATA_DIR = Path(\"./data\")\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Entorno listo. Los documentos se tomar√°n desde:\", DATA_DIR.resolve())\n",
        "\n",
        "# Listar archivos encontrados en ./data\n",
        "print(\"üì¶ Archivos detectados en ./data:\")\n",
        "for p in DATA_DIR.glob(\"*\"):\n",
        "    if p.suffix.lower() in [\".pdf\", \".docx\", \".doc\", \".txt\", \".md\", \".html\", \".htm\"]:\n",
        "        print(\" -\", p.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "AjuKEFSmvjh5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjuKEFSmvjh5",
        "outputId": "20ff8b2b-f04d-4802-9445-a4ad4d42cc2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'repo'...\n",
            "remote: Enumerating objects: 93, done.\u001b[K\n",
            "remote: Counting objects: 100% (93/93), done.\u001b[K\n",
            "remote: Compressing objects: 100% (81/81), done.\u001b[K\n",
            "remote: Total 93 (delta 36), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (93/93), 1.79 MiB | 4.71 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n",
            "'repo/data/GuiÃÅa de problemas frecuentes con equipo de coÃÅmputo.pdf' -> 'data/GuiÃÅa de problemas frecuentes con equipo de coÃÅmputo.pdf'\n",
            "'repo/data/Guia Win10 Win11.pdf' -> 'data/Guia Win10 Win11.pdf'\n",
            "'repo/data/PR-TI-SP-001 Procedimiento de Recepcion Diagnostico de Equipos de computo.pdf' -> 'data/PR-TI-SP-001 Procedimiento de Recepcion Diagnostico de Equipos de computo.pdf'\n",
            "'repo/requirements.txt' -> 'data/requirements.txt'\n",
            "'repo/README.md' -> 'data/README.md'\n",
            "total 2044\n",
            "drwxr-xr-x 3 root root    4096 Sep 15 23:38 .\n",
            "drwxr-xr-x 1 root root    4096 Sep 15 23:38 ..\n",
            "drwxr-xr-x 2 root root    4096 Sep 15 23:32 chroma\n",
            "-rw-r--r-- 1 root root   64818 Sep 15 23:38 GuiÃÅa de problemas frecuentes con equipo de coÃÅmputo.pdf\n",
            "-rw-r--r-- 1 root root  750349 Sep 15 23:38 Guia Win10 Win11.pdf\n",
            "-rw-r--r-- 1 root root 1253339 Sep 15 23:38 PR-TI-SP-001 Procedimiento de Recepcion Diagnostico de Equipos de computo.pdf\n",
            "-rw-r--r-- 1 root root      52 Sep 15 23:38 README.md\n",
            "-rw-r--r-- 1 root root     127 Sep 15 23:38 requirements.txt\n"
          ]
        }
      ],
      "source": [
        "# üöÄ Opci√≥n A: clonar tu repo y copiar documentos a ./data\n",
        "\n",
        "# 1) Clonar tu repositorio desde GitHub\n",
        "!rm -rf repo\n",
        "!git clone https://github.com/RocioPortillo86/SoporteTecnico-Rag.git repo\n",
        "\n",
        "# 2) Crear carpeta ./data si no existe\n",
        "!mkdir -p data\n",
        "\n",
        "# 3) Copiar documentos relevantes desde el repo a ./data\n",
        "!find repo -type f \\( -iname \"*.pdf\" -o -iname \"*.docx\" -o -iname \"*.doc\" -o -iname \"*.txt\" -o -iname \"*.md\" -o -iname \"*.html\" -o -iname \"*.htm\" \\) -exec cp -v {} data/ \\;\n",
        "\n",
        "# 4) Verificaci√≥n visual r√°pida\n",
        "!ls -la data | head -n 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "WYCOTmn_lqef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYCOTmn_lqef",
        "outputId": "a12e5c2d-5d5d-4143-c883-6e4fd32aec15"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pypdf._reader:Ignoring wrong pointing object 9 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 11 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 13 0 (offset 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Se cargaron 30 fragmentos desde 5 archivos\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader, UnstructuredFileLoader\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "folder_path = str(DATA_DIR)  # <-- usamos la carpeta definida en la celda 4\n",
        "\n",
        "# Buscar archivos comunes (recursivo)\n",
        "patterns = [\"**/*.pdf\", \"**/*.txt\", \"**/*.md\", \"**/*.docx\", \"**/*.html\", \"**/*.htm\"]\n",
        "file_paths = []\n",
        "for p in patterns:\n",
        "    file_paths.extend(glob(os.path.join(folder_path, p), recursive=True))\n",
        "\n",
        "if not file_paths:\n",
        "    raise FileNotFoundError(\n",
        "        f\"No se encontraron archivos en {folder_path}. \"\n",
        "        \"Coloca tus documentos en ./data.\"\n",
        "    )\n",
        "\n",
        "docs = []\n",
        "for path in file_paths:\n",
        "    try:\n",
        "        low = path.lower()\n",
        "        if low.endswith(\".pdf\"):\n",
        "            loader = PyPDFLoader(path)\n",
        "        elif low.endswith(\".txt\") or low.endswith(\".md\"):\n",
        "            loader = TextLoader(path)\n",
        "        else:\n",
        "            loader = UnstructuredFileLoader(path)  # Para DOCX/HTML\n",
        "        docs.extend(loader.load())\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error cargando {os.path.basename(path)}: {e}\")\n",
        "\n",
        "print(f\"‚úÖ Se cargaron {len(docs)} fragmentos desde {len(file_paths)} archivos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b83e77a",
      "metadata": {
        "id": "6b83e77a"
      },
      "source": [
        "## 2. Text Splitting into Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a4b8f501",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4b8f501",
        "outputId": "a1d358f3-e568-4397-ed64-43c05e9582cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Se crearon 51 fragmentos (chunk_size=1000, overlap=200)\n",
            "Ejemplo de fragmento:\n",
            "Archivo: desconocido\n",
            "Texto: Gu√≠a rapida de problemas frecuentes con equipo de c√≥mputo  Fuente de alimentaci√≥n  Problema: El ordenador se apaga de repente sin raz√≥n y hace mucho ruido  Soluci√≥n: Limpiar la fuente de poder por den ...\n"
          ]
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Definir par√°metros de fragmentaci√≥n\n",
        "CHUNK_SIZE = 1000\n",
        "CHUNK_OVERLAP = 200\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=CHUNK_SIZE,\n",
        "    chunk_overlap=CHUNK_OVERLAP\n",
        ")\n",
        "\n",
        "# Dividir los documentos cargados en fragmentos\n",
        "split_docs = text_splitter.split_documents(docs)\n",
        "\n",
        "print(f\"‚úÖ Se crearon {len(split_docs)} fragmentos (chunk_size={CHUNK_SIZE}, overlap={CHUNK_OVERLAP})\")\n",
        "\n",
        "# Mostrar vista previa del primer fragmento\n",
        "if split_docs:\n",
        "    print(\"Ejemplo de fragmento:\")\n",
        "    print(\"Archivo:\", split_docs[0].metadata.get(\"filename\", \"desconocido\"))\n",
        "    print(\"Texto:\", split_docs[0].page_content[:200].replace(\"\\n\", \" \"), \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d06e27f",
      "metadata": {
        "id": "8d06e27f"
      },
      "source": [
        "## 3. Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ec00fa4b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec00fa4b",
        "outputId": "fba245cb-37d8-4423-dcd5-71137d0452bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Embeddings listos con text-embedding-3-small\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Crear embeddings con el modelo moderno (m√°s r√°pido y econ√≥mico que ada-002)\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-3-small\",\n",
        "    api_key=openai_api_key   # aseg√∫rate que tu API Key est√° cargada en la celda 1\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Embeddings listos con text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72c82e20",
      "metadata": {
        "id": "72c82e20"
      },
      "source": [
        "## 4. Vector Stores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a3d89880",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3d89880",
        "outputId": "395cb5b7-7c90-44dc-8ebd-3f0260b6afd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Vector store creado y guardado en: /content/data/chroma\n"
          ]
        }
      ],
      "source": [
        "from langchain_chroma import Chroma\n",
        "from pathlib import Path\n",
        "\n",
        "# Carpeta donde se guardar√° la base vectorial\n",
        "PERSIST_DIR = Path(\"./data/chroma\")\n",
        "PERSIST_DIR.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Crear y persistir el vector store con los fragmentos y los embeddings ya definidos\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=split_docs,      # viene de la celda 8\n",
        "    embedding=embeddings,      # viene de la celda 10\n",
        "    persist_directory=str(PERSIST_DIR)\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"‚úÖ Vector store creado y guardado en: {PERSIST_DIR.resolve()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85da1ee7",
      "metadata": {
        "id": "85da1ee7"
      },
      "source": [
        "## 5. Retriving from the Persistant Vector Datastore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e9fd2322",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9fd2322",
        "outputId": "526f43f1-02ed-45e9-ec69-9f6825c87eb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Chroma reabierto desde: /content/data/chroma\n",
            "üîé Retriever listo (k=4)\n"
          ]
        }
      ],
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "# Reabrir Chroma desde disco usando los mismos embeddings\n",
        "vectordb = Chroma(\n",
        "    persist_directory=str(PERSIST_DIR),\n",
        "    embedding_function=embeddings\n",
        ")\n",
        "\n",
        "# Preparar el retriever (k=4 por defecto)\n",
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 4})\n",
        "\n",
        "print(\"‚úÖ Chroma reabierto desde:\", PERSIST_DIR.resolve())\n",
        "print(\"üîé Retriever listo (k=4)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4abf77e",
      "metadata": {
        "id": "d4abf77e"
      },
      "source": [
        "## 6. Retrivers in Langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "568bce4f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "568bce4f",
        "outputId": "83a9d72a-3f0a-4852-8e3f-535cfc42f17b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "‚ùì Pregunta 1: La computadora se apaga de repente, ¬øqu√© reviso?\n",
            "======================================================================\n",
            "**Diagn√≥stico breve**\n",
            "- La computadora puede estar experimentando sobrecalentamiento de la fuente de alimentaci√≥n o desgaste de la misma.\n",
            "\n",
            "**Pasos para resolver**\n",
            "1. Limpiar la fuente de poder por dentro para eliminar el polvo que puede estar causando el sobrecalentamiento.\n",
            "2. Verificar si la parte trasera de la fuente est√° sobrecalentada y mantener las tomas de aire limpias.\n",
            "3. Si el problema persiste, considerar el desgaste de la fuente y evaluar la posibilidad de cambiarla.\n",
            "\n",
            "**Verificaci√≥n**\n",
            "- Asegurarse de que la computadora encienda correctamente despu√©s de realizar la limpieza y verificar que no se apague de nuevo.\n",
            "\n",
            "**Notas / Advertencias**\n",
            "- Si la limpieza no resuelve el problema, puede ser necesario reemplazar la fuente de alimentaci√≥n.\n",
            "\n",
            "_Citas_: [archivo:p√°gina] [archivo:p√°gina]\n",
            "\n",
            "======================================================================\n",
            "‚ùì Pregunta 2: La impresora atasca las hojas, ¬øc√≥mo lo soluciono?\n",
            "======================================================================\n",
            "**Diagn√≥stico breve**\n",
            "- El papel se traba siempre en la impresora.\n",
            "\n",
            "**Pasos para resolver**\n",
            "1. Llevar la impresora a mantenimiento al servicio t√©cnico.\n",
            "2. Verificar si la bandeja de papel est√° muy cargada y reducir la cantidad de hojas si es necesario.\n",
            "3. Revisar el estado de las gomas de tracci√≥n, ya que podr√≠an no funcionar correctamente.\n",
            "\n",
            "**Verificaci√≥n**\n",
            "- Asegurarse de que la impresora funcione correctamente despu√©s del mantenimiento o ajustes realizados.\n",
            "\n",
            "**Notas / Advertencias**\n",
            "- Si el problema persiste, es recomendable consultar nuevamente al servicio t√©cnico.\n",
            "\n",
            "_Citas_: [archivo:p√°gina]\n",
            "\n",
            "======================================================================\n",
            "‚ùì Pregunta 3: ¬øC√≥mo restablecer la conexi√≥n a internet si no funciona?\n",
            "======================================================================\n",
            "**Diagn√≥stico breve**\n",
            "- La conexi√≥n a internet puede no funcionar por diversas razones, como problemas con la configuraci√≥n de red, controladores de la tarjeta de red o la tarjeta de red misma.\n",
            "\n",
            "**Pasos para resolver**\n",
            "1. Verifique la configuraci√≥n IP del dispositivo para asegurarse de que est√© correctamente configurada.\n",
            "2. Reinstale los controladores de la tarjeta de red para asegurarse de que est√©n actualizados y funcionando correctamente.\n",
            "3. Compruebe si dispone de la configuraci√≥n de red correcta para la red inal√°mbrica, incluyendo la contrase√±a.\n",
            "\n",
            "**Verificaci√≥n**\n",
            "- Aseg√∫rese de que el dispositivo pueda enviar y recibir datos despu√©s de realizar los pasos anteriores.\n",
            "\n",
            "**Notas / Advertencias**\n",
            "- Si el problema persiste, puede ser necesario revisar f√≠sicamente la tarjeta de red o consultar con el soporte t√©cnico del proveedor.\n",
            "\n",
            "_Citas_: [archivo:p√°gina] [archivo:p√°gina]\n",
            "\n",
            "======================================================================\n",
            "‚ùì Pregunta 4: ¬øQu√© hacer si la computadora hace mucho ruido?\n",
            "======================================================================\n",
            "**Diagn√≥stico breve**\n",
            "- La computadora puede estar haciendo ruido debido a la acumulaci√≥n de polvo en los ventiladores o en la fuente de alimentaci√≥n, lo que puede causar sobrecalentamiento.\n",
            "\n",
            "**Pasos para resolver**\n",
            "1. Apagar la computadora y desconectarla de la corriente.\n",
            "2. Limpiar la fuente de alimentaci√≥n por dentro para eliminar el polvo acumulado.\n",
            "3. Verificar y limpiar los ventiladores del sistema para asegurar un buen flujo de aire.\n",
            "\n",
            "**Verificaci√≥n**\n",
            "- Encender la computadora nuevamente y observar si el ruido ha disminuido o desaparecido.\n",
            "\n",
            "**Notas / Advertencias**\n",
            "- Aseg√∫rate de tener cuidado al abrir la fuente de alimentaci√≥n y de desconectar la computadora antes de realizar cualquier limpieza.\n",
            "\n",
            "_Citas_: [archivo:p√°gina] [archivo:p√°gina]\n",
            "\n",
            "======================================================================\n",
            "‚ùì Pregunta 5: ¬øQu√© informaci√≥n principal contienen estos documentos?\n",
            "======================================================================\n",
            "No hay evidencia suficiente en el CONTEXTO para responder a la pregunta sobre la informaci√≥n principal que contienen los documentos.\n",
            "\n",
            "_Citas_: [PR-TI-SP-001 Procedimiento de Recepcion Diagnostico de Equipos de computo.pdf:?] [PR-TI-SP-001 Procedimiento de Recepcion Diagnostico de Equipos de computo.pdf:?] [Guia Win10 Win11.pdf:3]\n"
          ]
        }
      ],
      "source": [
        "# --- Autorecuperaci√≥n de qa si no existe ---\n",
        "import os\n",
        "\n",
        "def _ensure_qa():\n",
        "    global qa\n",
        "    try:\n",
        "        qa  # ya existe\n",
        "        return\n",
        "    except NameError:\n",
        "        pass  # no existe, lo creamos\n",
        "\n",
        "    # Imports necesarios\n",
        "    from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "    try:\n",
        "        # preferible si NO tienes langchain-chroma instalado\n",
        "        from langchain_community.vectorstores import Chroma\n",
        "    except Exception:\n",
        "        # alternativa si usas el paquete separado\n",
        "        from langchain_chroma import Chroma\n",
        "    from langchain.chains import RetrievalQA\n",
        "\n",
        "    # Par√°metros desde env (√∫tiles en GitHub Actions); pon por defecto si no hay env\n",
        "    PERSIST_DIR = os.getenv(\"PERSIST_DIR\", \"data/chroma\")\n",
        "    EMB_MODEL   = os.getenv(\"MODEL_EMB\", \"text-embedding-3-small\")\n",
        "    LLM_MODEL   = os.getenv(\"LLM_MODEL\", \"gpt-4o-mini\")\n",
        "    OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "    assert OPENAI_API_KEY, \"Falta OPENAI_API_KEY\"\n",
        "\n",
        "    # Reabrir base y crear retriever + chain\n",
        "    embeddings = OpenAIEmbeddings(model=EMB_MODEL, api_key=OPENAI_API_KEY)\n",
        "    vectordb   = Chroma(persist_directory=PERSIST_DIR, embedding_function=embeddings)\n",
        "    retriever  = vectordb.as_retriever(search_kwargs={\"k\": 4})\n",
        "\n",
        "    llm = ChatOpenAI(model=LLM_MODEL, temperature=0, api_key=OPENAI_API_KEY)\n",
        "    qa = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        retriever=retriever,\n",
        "        return_source_documents=True,\n",
        "        chain_type=\"stuff\"\n",
        "    )\n",
        "\n",
        "_ensure_qa()\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "preguntas = [\n",
        "    \"La computadora se apaga de repente, ¬øqu√© reviso?\",\n",
        "    \"La impresora atasca las hojas, ¬øc√≥mo lo soluciono?\",\n",
        "    \"¬øC√≥mo restablecer la conexi√≥n a internet si no funciona?\",\n",
        "    \"¬øQu√© hacer si la computadora hace mucho ruido?\",\n",
        "    \"¬øQu√© informaci√≥n principal contienen estos documentos?\"\n",
        "]\n",
        "\n",
        "def _cite(meta: dict) -> str:\n",
        "    page = meta.get(\"page\") or meta.get(\"page_number\") or meta.get(\"source_page\") or \"?\"\n",
        "    fn = Path(meta.get(\"filename\", meta.get(\"source\",\"doc\"))).name\n",
        "    return f\"[{fn}:{page}]\"\n",
        "\n",
        "result_rows = []\n",
        "for i, q in enumerate(preguntas, 1):\n",
        "    out = qa.invoke({\"query\": q})\n",
        "    answer  = out.get(\"result\",\"\")\n",
        "    sources = out.get(\"source_documents\", []) or []\n",
        "    if \"_Citas_:\" not in answer and sources:\n",
        "        cites = \" \".join(_cite(d.metadata) for d in sources[:3])\n",
        "        answer += f\"\\n\\n_Citas_: {cites}\"\n",
        "    result_rows.append({\"#\": i, \"pregunta\": q, \"respuesta\": answer})\n",
        "\n",
        "print(f\"‚úÖ Generadas {len(result_rows)} respuestas\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KIFP37_-xUG0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIFP37_-xUG0",
        "outputId": "4f282465-13bc-4a01-b220-6585f7585ab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Resultados subidos a https://github.com/RocioPortillo86/SoporteTecnico-Rag/tree/main/results\n"
          ]
        }
      ],
      "source": [
        "# ‚úÖ 5 preguntas ‚Üí guarda MD/CSV en carpeta results/ (sin git push aqu√≠)\n",
        "\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "preguntas = [\n",
        "    \"La computadora se apaga de repente, ¬øqu√© reviso?\",\n",
        "    \"La impresora atasca las hojas, ¬øc√≥mo lo soluciono?\",\n",
        "    \"¬øC√≥mo restablecer la conexi√≥n a internet si no funciona?\",\n",
        "    \"¬øQu√© hacer si la computadora hace mucho ruido?\",\n",
        "    \"¬øQu√© informaci√≥n principal contienen estos documentos?\"\n",
        "]\n",
        "\n",
        "# --- hacer preguntas con qa ---\n",
        "from pathlib import Path as _P\n",
        "def _cite(meta: dict) -> str:\n",
        "    page = meta.get(\"page\") or meta.get(\"page_number\") or meta.get(\"source_page\") or \"?\"\n",
        "    fn = _P(meta.get(\"filename\", meta.get(\"source\",\"doc\"))).name\n",
        "    return f\"[{fn}:{page}]\"\n",
        "\n",
        "assert \"qa\" in globals(), \"Falta el objeto `qa` antes de esta celda.\"\n",
        "\n",
        "result_rows = []\n",
        "for i, q in enumerate(preguntas, 1):\n",
        "    out = qa.invoke({\"query\": q})\n",
        "    answer  = out.get(\"result\",\"\")\n",
        "    sources = out.get(\"source_documents\", []) or []\n",
        "    if \"_Citas_:\" not in answer and sources:\n",
        "        cites = \" \".join(_cite(d.metadata) for d in sources[:3])\n",
        "        answer += f\"\\n\\n_Citas_: {cites}\"\n",
        "    result_rows.append({\"#\": i, \"pregunta\": q, \"respuesta\": answer})\n",
        "\n",
        "# --- guardar en results/ ---\n",
        "now = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
        "results_dir = Path(\"results\")\n",
        "results_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "md_path  = results_dir / f\"QA_results_{now}.md\"\n",
        "csv_path = results_dir / f\"QA_results_{now}.csv\"\n",
        "\n",
        "with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(f\"# Resultados QA Soporte T√©cnico ‚Äî {now}\\n\\n\")\n",
        "    for row in result_rows:\n",
        "        f.write(f\"## ‚ùì Pregunta {row['#']}\\n{row['pregunta']}\\n\\n\")\n",
        "        f.write(f\"**Respuesta**\\n\\n{row['respuesta']}\\n\\n---\\n\\n\")\n",
        "\n",
        "pd.DataFrame(result_rows).to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(\"‚úÖ Archivos generados:\", md_path, csv_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MjNYVGr00RcI",
      "metadata": {
        "id": "MjNYVGr00RcI"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "rag_build",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
