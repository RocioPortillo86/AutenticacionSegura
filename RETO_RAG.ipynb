{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0ea4eedc",
      "metadata": {
        "id": "0ea4eedc"
      },
      "source": [
        "## 0. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c07e509",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c07e509",
        "outputId": "eb208f8b-a9c3-45e7-c978-266789790aa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "requests antes: 2.32.4\n",
            "3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "# Opcional: ver versión actual de requests\n",
        "import requests, sys\n",
        "print(\"requests antes:\", requests.__version__)\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mantener requests en 2.32.4 para que no se rompa google-colab\n",
        "%%bash\n",
        "cat > /tmp/constraints.txt << 'EOF'\n",
        "requests==2.32.4\n",
        "EOF\n",
        "\n",
        "# Instalar paquetes principales respetando la constraint de requests\n",
        "pip install -q -U -c /tmp/constraints.txt \\\n",
        "  langchain-community langchain-openai langchain-chroma chromadb pypdf tiktoken\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wW-rytnbg4EP",
        "outputId": "cefc7531-18f5-4a7c-8465-5ed20a1abcc0"
      },
      "id": "wW-rytnbg4EP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.5/2.5 MB 30.8 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 64.8/64.8 kB 4.8 MB/s eta 0:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "print(\"requests después:\", requests.__version__)"
      ],
      "metadata": {
        "id": "LM2LxBVehFoL",
        "outputId": "0957e7c9-99ef-4a53-c0d4-67b8f64338f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LM2LxBVehFoL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "requests después: 2.32.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b260d32",
      "metadata": {
        "id": "9b260d32"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain.schema import Document\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Obtener la API Key desde la variable de entorno (GitHub Actions -> Secrets)\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Inicializar el modelo LLM\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    api_key=openai_api_key,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Inicializar embeddings\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-3-small\",\n",
        "    api_key=openai_api_key\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "import shutil, pathlib\n",
        "\n",
        "# Carpeta destino\n",
        "BASE_DIR = \"/content/data/chroma\"\n",
        "os.makedirs(BASE_DIR, exist_ok=True)\n",
        "\n",
        "print(\"Entorno listo: data chroma\")\n",
        "print(\"Colab detectado. Sube tus PDFs/DOCX aquí:\")\n",
        "\n",
        "# Botón de subida\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Mover archivos al directorio destino\n",
        "for name in uploaded.keys():\n",
        "    shutil.move(name, os.path.join(BASE_DIR, pathlib.Path(name).name))\n",
        "\n",
        "print(f\"✅ {len(uploaded)} archivo(s) guardado(s) en {BASE_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "DYSLp9P6i7wJ",
        "outputId": "be0aadfc-ef68-4582-a089-f18d0dc56374"
      },
      "id": "DYSLp9P6i7wJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entorno listo: data chroma\n",
            "Colab detectado. Sube tus PDFs/DOCX aquí:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-26c1f0b0-7024-45e5-8764-f2cbfcca7f63\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-26c1f0b0-7024-45e5-8764-f2cbfcca7f63\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Guía de problemas frecuentes con equipo de cómputo.pdf to Guía de problemas frecuentes con equipo de cómputo.pdf\n",
            "Saving Guia Win10 Win11.pdf to Guia Win10 Win11.pdf\n",
            "Saving PR-TI-SP-001 Procedimiento de Recepcion Diagnostico de Equipos de computo.pdf to PR-TI-SP-001 Procedimiento de Recepcion Diagnostico de Equipos de computo.pdf\n",
            "✅ 3 archivo(s) guardado(s) en /content/data/chroma\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22e19bdb",
      "metadata": {
        "id": "22e19bdb"
      },
      "source": [
        "## 1. Extracting files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c51044c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c51044c",
        "outputId": "6a10b81c-d89d-402c-931c-1a003894a319"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pypdf._reader:Ignoring wrong pointing object 9 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 11 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 13 0 (offset 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Se cargaron 28 documentos desde 3 archivos\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader, UnstructuredFileLoader\n",
        "\n",
        "folder_path = BASE_DIR  # usa la carpeta de la celda 1\n",
        "\n",
        "# Buscar archivos comunes (recursivo)\n",
        "patterns = [\"**/*.pdf\", \"**/*.txt\", \"**/*.md\", \"**/*.docx\", \"**/*.html\", \"**/*.htm\"]\n",
        "file_paths = []\n",
        "for p in patterns:\n",
        "    file_paths.extend(glob(os.path.join(folder_path, p), recursive=True))\n",
        "\n",
        "if not file_paths:\n",
        "    raise FileNotFoundError(\n",
        "        f\"No se encontraron archivos en {folder_path}. \"\n",
        "        \"Sube documentos en la celda 1.\"\n",
        "    )\n",
        "\n",
        "docs = []\n",
        "for path in file_paths:\n",
        "    try:\n",
        "        low = path.lower()\n",
        "        if low.endswith(\".pdf\"):\n",
        "            loader = PyPDFLoader(path)\n",
        "        elif low.endswith(\".txt\") or low.endswith(\".md\"):\n",
        "            loader = TextLoader(path)\n",
        "        else:\n",
        "            # Para DOCX/HTML/etc. requiere instalar \"unstructured[standard]\" y python-magic\n",
        "            loader = UnstructuredFileLoader(path)\n",
        "        docs.extend(loader.load())\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Saltando {os.path.basename(path)}: {e}\")\n",
        "\n",
        "print(f\"✅ Se cargaron {len(docs)} documentos desde {len(file_paths)} archivos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b83e77a",
      "metadata": {
        "id": "6b83e77a"
      },
      "source": [
        "## 2. Text Splitting into Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4b8f501",
      "metadata": {
        "id": "a4b8f501",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce58aebd-2608-4fa1-f9a4-e447a01f57ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Se crearon 49 chunks\n"
          ]
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "split_docs = text_splitter.split_documents(docs)\n",
        "print(f\"✅ Se crearon {len(split_docs)} chunks\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d06e27f",
      "metadata": {
        "id": "8d06e27f"
      },
      "source": [
        "## 3. Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec00fa4b",
      "metadata": {
        "id": "ec00fa4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b371beb-9739-42dd-8059-eb07a303d85c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Embeddings listos (dim=1536)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Lee la API key (entorno o Colab Secrets)\n",
        "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    openai_api_key = openai_api_key or userdata.get(\"OPENAI_API_KEY\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "if not openai_api_key:\n",
        "    raise ValueError(\n",
        "        \"No se encontró OPENAI_API_KEY. \"\n",
        "        \"Configúrala como variable de entorno o en Colab (Runtime → Secrets).\"\n",
        "    )\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# 1536 dimensiones garantizadas\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-ada-002\",\n",
        "    api_key=openai_api_key\n",
        ")\n",
        "\n",
        "print(\"✅ Embeddings listos (dim=1536)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72c82e20",
      "metadata": {
        "id": "72c82e20"
      },
      "source": [
        "## 4. Vector Stores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3d89880",
      "metadata": {
        "id": "a3d89880",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abfb3a73-aba8-4861-a64e-a12013c5d497"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Vector store creado y guardado en: /content/chroma_db\n"
          ]
        }
      ],
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "PERSIST_DIR = \"/content/chroma_db\"\n",
        "\n",
        "# Crear y guardar automáticamente en disco\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=split_docs,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=PERSIST_DIR\n",
        ")\n",
        "\n",
        "print(f\"✅ Vector store creado y guardado en: {PERSIST_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85da1ee7",
      "metadata": {
        "id": "85da1ee7"
      },
      "source": [
        "## 5. Retriving from the Persistant Vector Datastore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9fd2322",
      "metadata": {
        "id": "e9fd2322",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f32dd91-3cca-44a3-beef-777413ca75ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Store reabierto y retriever listo.\n",
            "📁 Persist directory: /content/chroma_db\n",
            "🔎 Parámetros de búsqueda: {'k': 4}\n"
          ]
        }
      ],
      "source": [
        "# 5) Retriving from the Persistent Vector Datastore\n",
        "# ------------------------------------------------\n",
        "# Reabre el vector store persistente de Chroma y prepara el retriever.\n",
        "\n",
        "from langchain_chroma import Chroma\n",
        "import os\n",
        "\n",
        "# Verificación básica\n",
        "if not os.path.isdir(PERSIST_DIR):\n",
        "    raise FileNotFoundError(\n",
        "        f\"No existe el directorio de Chroma en {PERSIST_DIR}. \"\n",
        "        \"Asegúrate de haber creado el store en la sección anterior.\"\n",
        "    )\n",
        "\n",
        "# Reabrir el store (usa los mismos embeddings con los que se indexó)\n",
        "vectordb = Chroma(\n",
        "    persist_directory=PERSIST_DIR,\n",
        "    embedding_function=embeddings\n",
        ")\n",
        "\n",
        "# Crear el retriever (k = cantidad de chunks más similares a recuperar)\n",
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 4})\n",
        "\n",
        "print(\"✅ Store reabierto y retriever listo.\")\n",
        "print(f\"📁 Persist directory: {PERSIST_DIR}\")\n",
        "print(\"🔎 Parámetros de búsqueda:\", {\"k\": 4})\n",
        "\n",
        "# (Opcional) Prueba rápida de recuperación sin LLM:\n",
        "# ------------------------------------------------\n",
        "# Descomenta para inspeccionar qué chunks devuelve el retriever.\n",
        "# probe_query = \"¿Qué información principal contienen estos documentos?\"\n",
        "# docs_preview = retriever.get_relevant_documents(probe_query)\n",
        "# for i, d in enumerate(docs_preview, 1):\n",
        "#     src = d.metadata.get(\"source\", \"desconocida\")\n",
        "#     print(f\"\\n--- Documento #{i} ---\")\n",
        "#     print(\"Fuente:\", src)\n",
        "#     print(d.page_content[:500], \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4abf77e",
      "metadata": {
        "id": "d4abf77e"
      },
      "source": [
        "## 6. Retrivers in Langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "568bce4f",
      "metadata": {
        "id": "568bce4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "952de730-f7f5-4668-de57-974c3ee13868"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔎 Pregunta 1: ¿Qué información principal contienen estos documentos?\n",
            "🧠 Respuesta:\n",
            " Los documentos contienen información sobre procedimientos internos relacionados con la recepción, diagnóstico y reparación de equipos de cómputo. Incluyen secciones como \"Inicio\", \"Nuevo Registro\", \"Editar Registro\", \"Cerrar Reparación\", \"Imprimir Reporte\" y un anexo. También se menciona la revisión y emisión de un procedimiento específico con un código y la ubicación de la documentación en un módulo de control documental.\n",
            "\n",
            "🔎 Pregunta 2: ¿La impresora atasca las hojas?\n",
            "🧠 Respuesta:\n",
            " Sí, una de las fallas comunes es que el papel se traba siempre. La solución recomendada es llevar la impresora a mantenimiento al servicio técnico.\n"
          ]
        }
      ],
      "source": [
        "# 6) Retrieval con LLM (QA) y múltiples consultas\n",
        "# ------------------------------------------------\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# LLM\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    api_key=openai_api_key,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Chain de QA\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever\n",
        ")\n",
        "\n",
        "# Lista de preguntas\n",
        "queries = [\n",
        "    \"¿Qué información principal contienen estos documentos?\",\n",
        "    \"¿La impresora atasca las hojas?\"\n",
        "]\n",
        "\n",
        "# Ejecutar todas las consultas\n",
        "for i, query in enumerate(queries, 1):\n",
        "    result = qa.invoke({\"query\": query})\n",
        "    print(f\"\\n🔎 Pregunta {i}: {query}\")\n",
        "    print(\"🧠 Respuesta:\\n\", result.get(\"result\", result))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rag_build",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}